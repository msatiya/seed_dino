{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../../Datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in sorted(os.listdir(folder)) if f in [\"SEED.npz\", \"DEAP.npz\", \"DREAMER.npz\", \"SEED_IV.npz\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading DEAP.npz\n",
      "loading DREAMER.npz\n",
      "loading SEED.npz\n",
      "loading SEED_IV.npz\n"
     ]
    }
   ],
   "source": [
    "X, Y, S = [], [], []\n",
    "for file in files:\n",
    "    print(f\"loading {file}\")\n",
    "    dataset = np.load(os.path.join(folder, file))\n",
    "    X.append(dataset['X'])\n",
    "    Y.append(dataset['Y'])\n",
    "    S.append(dataset['subject'].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Analyzing the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________\n",
      " ######### DEAP.npz ######### \n",
      " S | Negative | Neutral | Positive | Total | Least per Class\n",
      "01 |   00638  |  00174  |  00348   | 1160  | 174\n",
      "02 |   00551  |  00145  |  00464   | 1160  | 145\n",
      "03 |   00522  |  00638  |  00000   | 1160  | 0\n",
      "04 |   00725  |  00174  |  00261   | 1160  | 174\n",
      "05 |   00493  |  00348  |  00319   | 1160  | 319\n",
      "06 |   00319  |  00493  |  00348   | 1160  | 319\n",
      "07 |   00435  |  00348  |  00377   | 1160  | 348\n",
      "08 |   00493  |  00348  |  00319   | 1160  | 319\n",
      "09 |   00522  |  00319  |  00319   | 1160  | 319\n",
      "10 |   00551  |  00261  |  00348   | 1160  | 261\n",
      "11 |   00580  |  00377  |  00203   | 1160  | 203\n",
      "12 |   00638  |  00087  |  00435   | 1160  | 87\n",
      "13 |   00725  |  00058  |  00377   | 1160  | 58\n",
      "14 |   00580  |  00232  |  00348   | 1160  | 232\n",
      "15 |   00609  |  00319  |  00232   | 1160  | 232\n",
      "16 |   00754  |  00261  |  00145   | 1160  | 145\n",
      "17 |   00522  |  00348  |  00290   | 1160  | 290\n",
      "18 |   00435  |  00348  |  00377   | 1160  | 348\n",
      "19 |   00522  |  00290  |  00348   | 1160  | 290\n",
      "20 |   00580  |  00261  |  00319   | 1160  | 261\n",
      "21 |   00551  |  00116  |  00493   | 1160  | 116\n",
      "22 |   00696  |  00174  |  00290   | 1160  | 174\n",
      "23 |   00580  |  00261  |  00319   | 1160  | 261\n",
      "24 |   00667  |  00232  |  00261   | 1160  | 232\n",
      "25 |   00667  |  00145  |  00348   | 1160  | 145\n",
      "26 |   00406  |  00377  |  00377   | 1160  | 377\n",
      "27 |   00464  |  00232  |  00464   | 1160  | 232\n",
      "28 |   00493  |  00232  |  00435   | 1160  | 232\n",
      "29 |   00551  |  00174  |  00435   | 1160  | 174\n",
      "30 |   00435  |  00377  |  00348   | 1160  | 348\n",
      "31 |   00580  |  00493  |  00087   | 1160  | 87\n",
      "32 |   00609  |  00319  |  00232   | 1160  | 232\n",
      "_____________________________\n",
      " ######### DREAMER.npz ######### \n",
      " S | Negative | Neutral | Positive | Total | Least per Class\n",
      "01 |   00372  |  00031  |  00155   | 558  | 31\n",
      "02 |   00279  |  00186  |  00093   | 558  | 93\n",
      "03 |   00279  |  00062  |  00217   | 558  | 62\n",
      "04 |   00372  |  00093  |  00093   | 558  | 93\n",
      "05 |   00310  |  00155  |  00093   | 558  | 93\n",
      "06 |   00186  |  00155  |  00217   | 558  | 155\n",
      "07 |   00341  |  00155  |  00062   | 558  | 62\n",
      "08 |   00403  |  00000  |  00155   | 558  | 0\n",
      "09 |   00155  |  00155  |  00248   | 558  | 155\n",
      "10 |   00310  |  00000  |  00248   | 558  | 0\n",
      "11 |   00341  |  00124  |  00093   | 558  | 93\n",
      "12 |   00248  |  00124  |  00186   | 558  | 124\n",
      "13 |   00310  |  00093  |  00155   | 558  | 93\n",
      "14 |   00341  |  00031  |  00186   | 558  | 31\n",
      "15 |   00279  |  00155  |  00124   | 558  | 124\n",
      "16 |   00310  |  00124  |  00124   | 558  | 124\n",
      "17 |   00372  |  00124  |  00062   | 558  | 62\n",
      "18 |   00279  |  00186  |  00093   | 558  | 93\n",
      "19 |   00124  |  00124  |  00310   | 558  | 124\n",
      "20 |   00341  |  00093  |  00124   | 558  | 93\n",
      "21 |   00217  |  00186  |  00155   | 558  | 155\n",
      "22 |   00341  |  00093  |  00124   | 558  | 93\n",
      "23 |   00341  |  00124  |  00093   | 558  | 93\n",
      "_____________________________\n",
      " ######### SEED.npz ######### \n",
      " S | Negative | Neutral | Positive | Total | Least per Class\n",
      "01 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "02 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "03 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "04 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "05 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "06 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "07 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "08 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "09 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "10 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "11 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "12 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "13 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "14 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "15 |   01380  |  01380  |  01380   | 4140  | 1380\n",
      "_____________________________\n",
      " ######### SEED_IV.npz ######### \n",
      " S | Negative | Neutral | Positive | Total | Least per Class\n",
      "01 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "02 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "03 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "04 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "05 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "06 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "07 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "08 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "09 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "10 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "11 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "12 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "13 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "14 |   00864  |  00432  |  00432   | 1728  | 432\n",
      "15 |   00864  |  00432  |  00432   | 1728  | 432\n"
     ]
    }
   ],
   "source": [
    "MIN_SAMPLES_PER_CLASS = []\n",
    "for file, x,y,s in zip(files, X,Y,S):\n",
    "    print(\"_____________________________\")\n",
    "    print(f\" ######### {file} ######### \")\n",
    "    print(\" S | Negative | Neutral | Positive | Total | Least per Class\")\n",
    "    min_samples_per_class = []\n",
    "    for subjectID in np.unique(s):\n",
    "        min_samples_per_class.append(min( sum(y[s==subjectID]==-1), sum(y[s==subjectID]==0), sum(y[s==subjectID]==1 ) ))\n",
    "        print(f\"{int(subjectID) :02d} |   {sum(y[s==subjectID]==-1) :05d}  |  {sum(y[s==subjectID]==0) :05d}  |  {sum(y[s==subjectID]==1) :05d}   | {sum(s==subjectID)}  | {min( sum(y[s==subjectID]==-1), sum(y[s==subjectID]==-0), sum(y[s==subjectID]==1 ) )}\")\n",
    "    MIN_SAMPLES_PER_CLASS.append(min_samples_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total samples:\n",
    "\n",
    "samples_per_subject_per_class * n_subjects * n_classes * n_datasources\n",
    "\n",
    "= 93 * 15 * 3 * 4\n",
    "\n",
    "= 16740\n",
    "\n",
    "Samples per datasource: 4185\n",
    "\n",
    "\n",
    "Test-Set: 3 subjects per datasource: 3*3*93 (*4) = 837 (3348)\n",
    "\n",
    "\n",
    "Precision: 1,2 % (0,03%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjects = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in S:\n",
    "    if len(np.unique(s)) < n_subjects: raise ValueError (\"The dataset holds samples of fewer than you want to use. Try again with a lower value of `number_of_subjects`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_per_subject_per_class = min([sorted(n, reverse=True)[n_subjects-1] for n in MIN_SAMPLES_PER_CLASS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_SAMPLED, Y_SAMPLED, S_SAMPLED = [], [], []\n",
    "for x,y,s,min_samples_per_class in zip(X,Y,S,MIN_SAMPLES_PER_CLASS):\n",
    "    eligible_subject_IDs = [n+1 for n in np.argsort(min_samples_per_class) if min_samples_per_class[n]>=n_samples_per_subject_per_class]\n",
    "    used_subjectIDs = np.random.choice(eligible_subject_IDs, n_subjects, replace=False)\n",
    "    x,y,s = shuffle(x,y,s, random_state=77)\n",
    "    x_sampled, y_sampled, s_sampled = [], [], []\n",
    "    for subjectID in used_subjectIDs:\n",
    "        for class_idx in [-1, 0, 1]:\n",
    "            x_sampled.append(x[np.bitwise_and(s==subjectID, y==class_idx)][:n_samples_per_subject_per_class])\n",
    "            y_sampled.append(y[np.bitwise_and(s==subjectID, y==class_idx)][:n_samples_per_subject_per_class])\n",
    "            s_sampled.append(s[np.bitwise_and(s==subjectID, y==class_idx)][:n_samples_per_subject_per_class])\n",
    "    X_SAMPLED.append(np.concatenate(x_sampled))\n",
    "    Y_SAMPLED.append(np.concatenate(y_sampled))\n",
    "    S_SAMPLED.append(np.concatenate(s_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________\n",
      " ######### DEAP.npz ######### \n",
      " S | Negative | Neutral | Positive | Total | Least per Class\n",
      "02 |   00093  |  00093  |  00093   | 279  | 93\n",
      "05 |   00093  |  00093  |  00093   | 279  | 93\n",
      "07 |   00093  |  00093  |  00093   | 279  | 93\n",
      "08 |   00093  |  00093  |  00093   | 279  | 93\n",
      "10 |   00093  |  00093  |  00093   | 279  | 93\n",
      "15 |   00093  |  00093  |  00093   | 279  | 93\n",
      "18 |   00093  |  00093  |  00093   | 279  | 93\n",
      "20 |   00093  |  00093  |  00093   | 279  | 93\n",
      "22 |   00093  |  00093  |  00093   | 279  | 93\n",
      "26 |   00093  |  00093  |  00093   | 279  | 93\n",
      "27 |   00093  |  00093  |  00093   | 279  | 93\n",
      "28 |   00093  |  00093  |  00093   | 279  | 93\n",
      "29 |   00093  |  00093  |  00093   | 279  | 93\n",
      "30 |   00093  |  00093  |  00093   | 279  | 93\n",
      "32 |   00093  |  00093  |  00093   | 279  | 93\n",
      "_____________________________\n",
      " ######### DREAMER.npz ######### \n",
      " S | Negative | Neutral | Positive | Total | Least per Class\n",
      "02 |   00093  |  00093  |  00093   | 279  | 93\n",
      "04 |   00093  |  00093  |  00093   | 279  | 93\n",
      "05 |   00093  |  00093  |  00093   | 279  | 93\n",
      "06 |   00093  |  00093  |  00093   | 279  | 93\n",
      "09 |   00093  |  00093  |  00093   | 279  | 93\n",
      "11 |   00093  |  00093  |  00093   | 279  | 93\n",
      "12 |   00093  |  00093  |  00093   | 279  | 93\n",
      "13 |   00093  |  00093  |  00093   | 279  | 93\n",
      "15 |   00093  |  00093  |  00093   | 279  | 93\n",
      "16 |   00093  |  00093  |  00093   | 279  | 93\n",
      "19 |   00093  |  00093  |  00093   | 279  | 93\n",
      "20 |   00093  |  00093  |  00093   | 279  | 93\n",
      "21 |   00093  |  00093  |  00093   | 279  | 93\n",
      "22 |   00093  |  00093  |  00093   | 279  | 93\n",
      "23 |   00093  |  00093  |  00093   | 279  | 93\n",
      "_____________________________\n",
      " ######### SEED.npz ######### \n",
      " S | Negative | Neutral | Positive | Total | Least per Class\n",
      "01 |   00093  |  00093  |  00093   | 279  | 93\n",
      "02 |   00093  |  00093  |  00093   | 279  | 93\n",
      "03 |   00093  |  00093  |  00093   | 279  | 93\n",
      "04 |   00093  |  00093  |  00093   | 279  | 93\n",
      "05 |   00093  |  00093  |  00093   | 279  | 93\n",
      "06 |   00093  |  00093  |  00093   | 279  | 93\n",
      "07 |   00093  |  00093  |  00093   | 279  | 93\n",
      "08 |   00093  |  00093  |  00093   | 279  | 93\n",
      "09 |   00093  |  00093  |  00093   | 279  | 93\n",
      "10 |   00093  |  00093  |  00093   | 279  | 93\n",
      "11 |   00093  |  00093  |  00093   | 279  | 93\n",
      "12 |   00093  |  00093  |  00093   | 279  | 93\n",
      "13 |   00093  |  00093  |  00093   | 279  | 93\n",
      "14 |   00093  |  00093  |  00093   | 279  | 93\n",
      "15 |   00093  |  00093  |  00093   | 279  | 93\n",
      "_____________________________\n",
      " ######### SEED_IV.npz ######### \n",
      " S | Negative | Neutral | Positive | Total | Least per Class\n",
      "01 |   00093  |  00093  |  00093   | 279  | 93\n",
      "02 |   00093  |  00093  |  00093   | 279  | 93\n",
      "03 |   00093  |  00093  |  00093   | 279  | 93\n",
      "04 |   00093  |  00093  |  00093   | 279  | 93\n",
      "05 |   00093  |  00093  |  00093   | 279  | 93\n",
      "06 |   00093  |  00093  |  00093   | 279  | 93\n",
      "07 |   00093  |  00093  |  00093   | 279  | 93\n",
      "08 |   00093  |  00093  |  00093   | 279  | 93\n",
      "09 |   00093  |  00093  |  00093   | 279  | 93\n",
      "10 |   00093  |  00093  |  00093   | 279  | 93\n",
      "11 |   00093  |  00093  |  00093   | 279  | 93\n",
      "12 |   00093  |  00093  |  00093   | 279  | 93\n",
      "13 |   00093  |  00093  |  00093   | 279  | 93\n",
      "14 |   00093  |  00093  |  00093   | 279  | 93\n",
      "15 |   00093  |  00093  |  00093   | 279  | 93\n"
     ]
    }
   ],
   "source": [
    "for file, x_sampled,y_sampled,s_sampled in zip(files, X_SAMPLED,Y_SAMPLED,S_SAMPLED):\n",
    "    print(\"_____________________________\")\n",
    "    print(f\" ######### {file} ######### \")\n",
    "    print(\" S | Negative | Neutral | Positive | Total | Least per Class\")\n",
    "    for subjectID in np.unique(s_sampled):\n",
    "        print(f\"{int(subjectID) :02d} |   {sum(y_sampled[s_sampled==subjectID]==-1) :05d}  |  {sum(y_sampled[s_sampled==subjectID]==0) :05d}  |  {sum(y_sampled[s_sampled==subjectID]==1) :05d}   | {sum(s_sampled==subjectID)}  | {min( sum(y_sampled[s_sampled==subjectID]==-1), sum(y_sampled[s_sampled==subjectID]==-0), sum(y_sampled[s_sampled==subjectID]==1 ) )}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Assure samples of each data-sources at same index have same label [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffled_indices = torch.randperm(len(X_SAMPLED[0]))\n",
    "#for datasource_idx, (file, x_sampled,y_sampled,s_sampled) in enumerate(zip(files, X_SAMPLED,Y_SAMPLED,S_SAMPLED)):\n",
    "#    sorted_indices = np.argsort(y_sampled)\n",
    "#    X_SAMPLED[datasource_idx] = x_sampled[sorted_indices][shuffled_indices]\n",
    "#    Y_SAMPLED[datasource_idx] = y_sampled[sorted_indices][shuffled_indices]\n",
    "#    S_SAMPLED[datasource_idx] = s_sampled[sorted_indices][shuffled_indices]\n",
    "#\n",
    "#\n",
    "## --> Don't do it, as this is only possible if we have labeled data across ALL data-sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Verifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing dataset number 0\n",
      "Analyzing dataset number 1\n",
      "Analyzing dataset number 2\n",
      "Analyzing dataset number 3\n"
     ]
    }
   ],
   "source": [
    "for dataset_idx, (x_sampled,y_sampled,s_sampled, x, y, s) in enumerate(zip(X_SAMPLED,Y_SAMPLED,S_SAMPLED, X, Y, S)):\n",
    "    print(f\"Analyzing dataset number {dataset_idx}\")\n",
    "# check if some exemplary x_sampled per data-source are correctly labeled:\n",
    "    exemplary_sample_IDs = np.random.choice(x_sampled.shape[0], size=10, replace=False)\n",
    "    for exemplary_x, exemplary_y, exemplary_s in zip(x_sampled[exemplary_sample_IDs], y_sampled[exemplary_sample_IDs], s_sampled[exemplary_sample_IDs]):\n",
    "        idx = (x==exemplary_x).all(axis=(1,2)).nonzero()[0]\n",
    "        # 1. occur only once in x_sampled\n",
    "        if len(idx)>1:\n",
    "            continue\n",
    "        assert len(idx)==1\n",
    "        # 2. the right label\n",
    "        assert y[idx] == exemplary_y\n",
    "        # 3. the right subject id\n",
    "        assert s[idx] == exemplary_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Split-off Test-Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the samples of 3 subjects per dataset as test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, S_train = [], [], []\n",
    "X_test, Y_test, S_test = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELIGIBLE_TEST_SUBJECTS = [np.unique(s).tolist() for s in S_SAMPLED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SUBJECTS = [sorted(np.random.choice(eligible_test_subjects, 3, replace=False)) for eligible_test_subjects in ELIGIBLE_TEST_SUBJECTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,s,test_subjects in zip(X_SAMPLED, Y_SAMPLED, S_SAMPLED, TEST_SUBJECTS):\n",
    "    condition = np.bitwise_or(np.bitwise_or(s==test_subjects[0], s==test_subjects[1]), s==test_subjects[2])\n",
    "    X_train.append(x[np.invert(condition)])\n",
    "    Y_train.append(y[np.invert(condition)])\n",
    "    S_train.append(s[np.invert(condition)])\n",
    "    X_test.append(x[condition])\n",
    "    Y_test.append(y[condition])\n",
    "    S_test.append(s[condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 32, 256)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"X_train\": X_train,\n",
    "        \"Y_train\": Y_train,\n",
    "        \"S_train\": S_train\n",
    "    },\n",
    "    '../Datasets/multisource_train.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"X_test\": X_test,\n",
    "        \"Y_test\": Y_test,\n",
    "        \"S_test\": S_test\n",
    "    },\n",
    "    '../Datasets/multisource_test.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_train_data = torch.load('../Datasets/multisource_train.pt')\n",
    "verify_X_train = verify_train_data['X_train']\n",
    "verify_Y_train = verify_train_data['Y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "(X_train[2]==verify_X_train[2]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load('../Datasets/multisource_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset['X_train']\n",
    "Y_train = dataset['Y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  0.,  1.]), array([1116, 1116, 1116]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train[3], return_counts=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07ef97a7904fc87587e227336206a53864494cfeab337e25080fe4eff6001455"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lightning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
